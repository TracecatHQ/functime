{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Benchmarks\n",
    "---\n",
    "\n",
    "This walkthrough serves as a benchmark for comparing `functime` with `tsfresh` feature extraction functions. We begin the analysis by evaluating the speed of feature extraction across time series of three different sizes: 100K, 1M, and 9M. Next, we assess the speed in a groupby and aggregation context, making a performance comparison between functime with polars and tsfresh using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install perfplot\n",
    "%pip install pandas\n",
    "%pip install tsfresh\n",
    "%pip install functime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import pandas as pd\n",
    "import perfplot\n",
    "import polars as pl\n",
    "from tsfresh.feature_extraction import feature_calculators as tsfresh\n",
    "\n",
    "from functime import feature_extractors as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(100)\n",
    "pl.Config.set_fmt_str_lengths(60)\n",
    "pl.Config.set_tbl_hide_column_data_types(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup for the comparison\n",
    "---\n",
    "We are using the M4 dataset. We create a `pd.DataFrame` and `pl.DataFrame` and we define a list of dictionary with the following structure:\n",
    "<br>\n",
    "(<br>\n",
    "&emsp;  `<functime_function>`,<br>\n",
    "&emsp;  `<tsfresh_function>`,<br>\n",
    "&emsp;  `<functime_parameters>`,<br>\n",
    "&emsp;   `<tsfresh_parameters>`<br>\n",
    ")<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_M4_DATASET = \"../../data/m4_1d_train.parquet/*/*\"\n",
    "\n",
    "DF_PANDAS = (\n",
    "    pd.melt(pd.read_parquet(_M4_DATASET))\n",
    "    .drop(columns=[\"variable\"])\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "DF_PL_EAGER = (\n",
    "    pl.read_parquet(_M4_DATASET).drop(\"V1\").melt().drop(\"variable\").drop_nulls()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNC_PARAMS_BENCH = [\n",
    "    (fe.absolute_energy, tsfresh.abs_energy, {}, {}),\n",
    "    (fe.absolute_maximum, tsfresh.absolute_maximum, {}, {}),\n",
    "    (fe.absolute_sum_of_changes, tsfresh.absolute_sum_of_changes, {}, {}),\n",
    "    (\n",
    "        fe.lempel_ziv_complexity,\n",
    "        tsfresh.lempel_ziv_complexity,\n",
    "        {\"threshold\": (pl.col(\"value\").max() - pl.col(\"value\").min()) / 2},\n",
    "        {\"bins\": 2},\n",
    "    ),\n",
    "    (\n",
    "        fe.approximate_entropy,\n",
    "        tsfresh.approximate_entropy,\n",
    "        {\"run_length\": 2, \"filtering_level\": 0.5},\n",
    "        {\"m\": 2, \"r\": 0.5},\n",
    "    ),\n",
    "    # (fe.augmented_dickey_fuller, tsfresh.augmented_dickey_fuller, \"param\")\n",
    "    (fe.autocorrelation, tsfresh.autocorrelation, {\"n_lags\": 4}, {\"lag\": 4}),\n",
    "    (\n",
    "        fe.autoregressive_coefficients,\n",
    "        tsfresh.ar_coefficient,\n",
    "        {\"n_lags\": 4},\n",
    "        {\"param\": [{\"coeff\": i, \"k\": 4}] for i in range(5)},\n",
    "    ),\n",
    "    (fe.benford_correlation, tsfresh.benford_correlation, {}, {}),\n",
    "    (fe.binned_entropy, tsfresh.binned_entropy, {\"bin_count\": 10}, {\"max_bins\": 10}),\n",
    "    (fe.c3, tsfresh.c3, {\"n_lags\": 10}, {\"lag\": 10}),\n",
    "    (\n",
    "        fe.change_quantiles,\n",
    "        tsfresh.change_quantiles,\n",
    "        {\"q_low\": 0.1, \"q_high\": 0.9, \"is_abs\": True},\n",
    "        {\"ql\": 0.1, \"qh\": 0.9, \"isabs\": True, \"f_agg\": \"mean\"},\n",
    "    ),\n",
    "    (fe.cid_ce, tsfresh.cid_ce, {\"normalize\": True}, {\"normalize\": True}),\n",
    "    (fe.count_above, tsfresh.count_above, {\"threshold\": 0.0}, {\"t\": 0.0}),\n",
    "    (fe.count_above_mean, tsfresh.count_above_mean, {}, {}),\n",
    "    (fe.count_below, tsfresh.count_below, {\"threshold\": 0.0}, {\"t\": 0.0}),\n",
    "    (fe.count_below_mean, tsfresh.count_below_mean, {}, {}),\n",
    "    # (fe.cwt_coefficients, tsfresh.cwt_coefficients, {\"widths\": (1, 2, 3), \"n_coefficients\": 2},{\"param\": {\"widths\": (1, 2, 3), \"coeff\": 2, \"w\": 1}}),\n",
    "    (\n",
    "        fe.energy_ratios,\n",
    "        tsfresh.energy_ratio_by_chunks,\n",
    "        {\"n_chunks\": 6},\n",
    "        {\"param\": [{\"num_segments\": 6, \"segment_focus\": i} for i in range(6)]},\n",
    "    ),\n",
    "    (fe.first_location_of_maximum, tsfresh.first_location_of_maximum, {}, {}),\n",
    "    (fe.first_location_of_minimum, tsfresh.first_location_of_minimum, {}, {}),\n",
    "    # (fe.fourier_entropy, tsfresh.fourier_entropy, {\"n_bins\": 10}, {\"bins\": 10}),\n",
    "    # (fe.friedrich_coefficients, tsfresh.friedrich_coefficients, {\"polynomial_order\": 3, \"n_quantiles\": 30}, {\"params\": [{\"m\": 3, \"r\": 30}]}),\n",
    "    (fe.has_duplicate, tsfresh.has_duplicate, {}, {}),\n",
    "    (fe.has_duplicate_max, tsfresh.has_duplicate_max, {}, {}),\n",
    "    (fe.has_duplicate_min, tsfresh.has_duplicate_min, {}, {}),\n",
    "    (\n",
    "        fe.index_mass_quantile,\n",
    "        tsfresh.index_mass_quantile,\n",
    "        {\"q\": 0.5},\n",
    "        {\"param\": [{\"q\": 0.5}]},\n",
    "    ),\n",
    "    (\n",
    "        fe.large_standard_deviation,\n",
    "        tsfresh.large_standard_deviation,\n",
    "        {\"ratio\": 0.25},\n",
    "        {\"r\": 0.25},\n",
    "    ),\n",
    "    (fe.last_location_of_maximum, tsfresh.last_location_of_maximum, {}, {}),\n",
    "    (fe.last_location_of_minimum, tsfresh.last_location_of_minimum, {}, {}),\n",
    "    # (fe.lempel_ziv_complexity, tsfresh.lempel_ziv_complexity, {\"n_bins\": 5}, {\"bins\": 5}),\n",
    "    (\n",
    "        fe.linear_trend,\n",
    "        tsfresh.linear_trend,\n",
    "        {},\n",
    "        {\n",
    "            \"param\": [\n",
    "                {\"attr\": \"pvalue\"},\n",
    "                {\"attr\": \"rvalue\"},\n",
    "                {\"attr\": \"intercept\"},\n",
    "                {\"attr\": \"slope\"},\n",
    "                {\"attr\": \"stderr\"},\n",
    "            ]\n",
    "        },\n",
    "    ),\n",
    "    (fe.longest_streak_above_mean, tsfresh.longest_strike_above_mean, {}, {}),\n",
    "    (fe.longest_streak_below_mean, tsfresh.longest_strike_below_mean, {}, {}),\n",
    "    (fe.mean_abs_change, tsfresh.mean_abs_change, {}, {}),\n",
    "    (fe.mean_change, tsfresh.mean_change, {}, {}),\n",
    "    (\n",
    "        fe.mean_n_absolute_max,\n",
    "        tsfresh.mean_n_absolute_max,\n",
    "        {\"n_maxima\": 20},\n",
    "        {\"number_of_maxima\": 20},\n",
    "    ),\n",
    "    (\n",
    "        fe.mean_second_derivative_central,\n",
    "        tsfresh.mean_second_derivative_central,\n",
    "        {},\n",
    "        {},\n",
    "    ),\n",
    "    (\n",
    "        fe.number_crossings,\n",
    "        tsfresh.number_crossing_m,\n",
    "        {\"crossing_value\": 0.0},\n",
    "        {\"m\": 0.0},\n",
    "    ),\n",
    "    (fe.number_cwt_peaks, tsfresh.number_cwt_peaks, {\"max_width\": 5}, {\"n\": 5}),\n",
    "    (fe.number_peaks, tsfresh.number_peaks, {\"support\": 5}, {\"n\": 5}),\n",
    "    # (fe.partial_autocorrelation, tsfresh.partial_autocorrelation, \"param\"),\n",
    "    (\n",
    "        fe.percent_reoccurring_values,\n",
    "        tsfresh.percentage_of_reoccurring_values_to_all_values,\n",
    "        {},\n",
    "        {},\n",
    "    ),\n",
    "    (\n",
    "        fe.percent_reoccurring_points,\n",
    "        tsfresh.percentage_of_reoccurring_datapoints_to_all_datapoints,\n",
    "        {},\n",
    "        {},\n",
    "    ),\n",
    "    (\n",
    "        fe.permutation_entropy,\n",
    "        tsfresh.permutation_entropy,\n",
    "        {\"tau\": 1, \"n_dims\": 3},\n",
    "        {\"tau\": 1, \"dimension\": 3},\n",
    "    ),\n",
    "    (\n",
    "        fe.range_count,\n",
    "        tsfresh.range_count,\n",
    "        {\"lower\": 0, \"upper\": 9, \"closed\": \"none\"},\n",
    "        {\"min\": 0, \"max\": 9},\n",
    "    ),\n",
    "    (fe.ratio_beyond_r_sigma, tsfresh.ratio_beyond_r_sigma, {\"ratio\": 2}, {\"r\": 2}),\n",
    "    (\n",
    "        fe.ratio_n_unique_to_length,\n",
    "        tsfresh.ratio_value_number_to_time_series_length,\n",
    "        {},\n",
    "        {},\n",
    "    ),\n",
    "    (fe.root_mean_square, tsfresh.root_mean_square, {}, {}),\n",
    "    (fe.sample_entropy, tsfresh.sample_entropy, {}, {}),\n",
    "    (\n",
    "        fe.spkt_welch_density,\n",
    "        tsfresh.spkt_welch_density,\n",
    "        {\"n_coeffs\": 10},\n",
    "        {\"param\": [{\"coeff\": i} for i in range(10)]},\n",
    "    ),\n",
    "    (fe.sum_reoccurring_points, tsfresh.sum_of_reoccurring_data_points, {}, {}),\n",
    "    (fe.sum_reoccurring_values, tsfresh.sum_of_reoccurring_values, {}, {}),\n",
    "    (\n",
    "        fe.symmetry_looking,\n",
    "        tsfresh.symmetry_looking,\n",
    "        {\"ratio\": 0.25},\n",
    "        {\"param\": [{\"r\": 0.25}]},\n",
    "    ),\n",
    "    (\n",
    "        fe.time_reversal_asymmetry_statistic,\n",
    "        tsfresh.time_reversal_asymmetry_statistic,\n",
    "        {\"n_lags\": 3},\n",
    "        {\"lag\": 3},\n",
    "    ),\n",
    "    (fe.variation_coefficient, tsfresh.variation_coefficient, {}, {}),\n",
    "    (fe.var_gt_std, tsfresh.variance_larger_than_standard_deviation, {}, {}),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Benchmark core functions\n",
    "---\n",
    "Benchmark core function for time series' length of 100_000, 1_000_000 and 9_000_000. (Except 10_000 for `approximate_entropy` and 10_000/100_000 for `number_cwt_peaks` and `sample_entropy`). `all_benchmarks()` iterates through the elements in the `FUNC_PARAMS_BENCH` list and invoke `benchmark()` for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(\n",
    "    f_feat: Callable, ts_feat: Callable, f_params: dict, ts_params: dict, is_expr: bool\n",
    "):\n",
    "    if f_feat.__name__ == \"approximate_entropy\":\n",
    "        n_range = [10_000]\n",
    "    elif f_feat.__name__ in (\n",
    "        \"number_cwt_peaks\",\n",
    "        \"sample_entropy\",\n",
    "        \"lempel_ziv_complexity\",\n",
    "    ):\n",
    "        n_range = [10_000, 100_000]\n",
    "    else:\n",
    "        n_range = [10_000, 100_000, 1_000_000, 9_000_000]\n",
    "    benchmark = perfplot.bench(\n",
    "        setup=lambda n: (DF_PL_EAGER.head(n), DF_PANDAS.head(n)),\n",
    "        kernels=[\n",
    "            lambda x, _y: f_feat(x[\"value\"], **f_params)\n",
    "            if not is_expr\n",
    "            else x.select(f_feat(pl.col(\"value\"), **f_params)),\n",
    "            lambda _x, y: ts_feat(y[\"value\"], **ts_params),\n",
    "        ],\n",
    "        n_range=n_range,\n",
    "        equality_check=False,\n",
    "        labels=[\"functime\", \"tsfresh\"],\n",
    "    )\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_benchmarks(params: list[tuple], is_expr: bool) -> list:\n",
    "    bench_df = pl.DataFrame(\n",
    "        schema={\n",
    "            \"Feature name\": pl.Utf8,\n",
    "            \"n\": pl.Int64,\n",
    "            \"functime (ms)\": pl.Float64,\n",
    "            \"tfresh (ms)\": pl.Float64,\n",
    "            \"diff (ms)\": pl.Float64,\n",
    "            \"diff %\": pl.Float64,\n",
    "            \"speedup\": pl.Float64,\n",
    "        }\n",
    "    )\n",
    "    for x in params:\n",
    "        try:\n",
    "            f_feat = x[0]\n",
    "            print(f\"Feature: {f_feat.__name__}\")\n",
    "            bench = benchmark(\n",
    "                f_feat=f_feat,\n",
    "                ts_feat=x[1],\n",
    "                f_params=x[2],\n",
    "                ts_params=x[3],\n",
    "                is_expr=is_expr,\n",
    "            )\n",
    "            bench_df = pl.concat(\n",
    "                [\n",
    "                    pl.DataFrame(\n",
    "                        {\n",
    "                            \"Feature name\": [x[0].__name__] * len(bench.n_range),\n",
    "                            \"n\": bench.n_range,\n",
    "                            \"functime (ms)\": bench.timings_s[0] * 1_000,\n",
    "                            \"tfresh (ms)\": bench.timings_s[1] * 1_000,\n",
    "                            \"diff (ms)\": (bench.timings_s[0] - bench.timings_s[1])\n",
    "                            * 1_000,\n",
    "                            \"diff %\": 100\n",
    "                            * (bench.timings_s[0] - bench.timings_s[1])\n",
    "                            / bench.timings_s[1],\n",
    "                            \"speedup\": bench.timings_s[1] / bench.timings_s[0],\n",
    "                        }\n",
    "                    ),\n",
    "                    bench_df,\n",
    "                ]\n",
    "            )\n",
    "        except ValueError:\n",
    "            print(f\"Failed to compute feature {x[0].__name__}\")\n",
    "        except ImportError:\n",
    "            print(f\"Failed to import feature {x[0].__name__}\")\n",
    "        except TypeError:\n",
    "            print(f\"Feature {x[0].__name__} not implemented for pl.Expr\")\n",
    "    return bench_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run benchmarks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to prettify benchmark results\n",
    "def table_prettifier(df: pl.DataFrame, n: int):\n",
    "    table = (\n",
    "        df.filter(pl.col(\"n\") == n)\n",
    "        .drop(\"n\")\n",
    "        .sort(\"speedup\", descending=True)\n",
    "        .with_columns(\n",
    "            pl.when(pl.exclude(\"Feature name\").abs() < 0.1)\n",
    "            .then(pl.exclude(\"Feature name\").round(4))\n",
    "            .when(pl.exclude(\"Feature name\").abs() < 1)\n",
    "            .then(pl.exclude(\"Feature name\").round(2))\n",
    "            .when(pl.exclude(\"Feature name\").abs() < 30)\n",
    "            .then(pl.exclude(\"Feature name\").round(1))\n",
    "            .otherwise(pl.exclude(\"Feature name\").round(1))\n",
    "        )\n",
    "        .with_columns(speedup=\"x \" + pl.col(\"speedup\").cast(pl.Utf8))\n",
    "    )\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "bench_expr = all_benchmarks(params=FUNC_PARAMS_BENCH, is_expr=True)\n",
    "bench_series = all_benchmarks(params=FUNC_PARAMS_BENCH, is_expr=False)\n",
    "\n",
    "# Lazy benchmarks\n",
    "df_expr_10k = table_prettifier(bench_expr, n=10_000)\n",
    "df_expr_100k = table_prettifier(bench_expr, n=100_000)\n",
    "df_expr_1m = table_prettifier(bench_expr, n=1_000_000)\n",
    "df_expr_9m = table_prettifier(bench_expr, n=9_000_000)\n",
    "\n",
    "# Eager benchmarks\n",
    "df_series_10k = table_prettifier(bench_series, n=10_000)\n",
    "df_series_100k = table_prettifier(bench_series, n=100_000)\n",
    "df_series_1m = table_prettifier(bench_series, n=1_000_000)\n",
    "df_series_9m = table_prettifier(bench_series, n=9_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Benchmark results\n",
    "---\n",
    "\n",
    "Display 8 tables:\n",
    "- For `pl.Series`: 10k, 100k, 1M and 9M rows\n",
    "- For `pl.Expr`: 10k, 100k, 1M and 9M rows\n",
    "\n",
    "Each table contains the execution time (ms) for tsfresh and functime, the difference, the difference in % and the speedup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Results for `pl.Expr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10k expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expr_10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100k expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expr_100k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1M expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expr_1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9M expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expr_9m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Results for `pl.Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10k series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100k series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_100k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1M series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9M series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_9m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Benchmark `Group by / Aggregation` context\n",
    "\n",
    "Benchmark combining functime's feature extraction and polars' `Group by / Aggregation` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SP500_DATASET = \"../../data/sp500.parquet\"\n",
    "\n",
    "SP500_PANDAS = pd.read_parquet(_SP500_DATASET)\n",
    "SP500_PL_EAGER = pl.read_parquet(_SP500_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare `tsfresh` using `pandas' groupby`  with  `functime` using `polars' groupby` such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "SP500_PANDAS.groupby(by=\"ticker\")[\"price\"].agg(tsfresh.number_peaks, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "SP500_PL_EAGER.group_by(pl.col(\"ticker\")).agg(\n",
    "    pl.col(\"price\").ts.number_peaks(support=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we examine the previous benchmark, we can see that the `number_peaks` operation is approximately **2.5** times faster when using `functime` compared to `tsfresh`.\n",
    "\n",
    "In the `groupby` context, it's **10** times faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_groupby_context(\n",
    "    f_feat: Callable, ts_feat: Callable, f_params: dict, ts_params: dict\n",
    "):\n",
    "    if f_feat.__name__ == \"lempel_ziv_complexity\":\n",
    "        f_params = {\"threshold\": (pl.col(\"price\").max() - pl.col(\"price\").min()) / 2}\n",
    "    benchmark = perfplot.bench(\n",
    "        setup=lambda _n: (SP500_PL_EAGER, SP500_PANDAS),\n",
    "        kernels=[\n",
    "            lambda x, _y: x.group_by(pl.col(\"ticker\")).agg(\n",
    "                f_feat(pl.col(\"price\"), **f_params)\n",
    "            ),  # functime + polars groupby\n",
    "            lambda _x, y: y.groupby(\"ticker\")[\"price\"].agg(\n",
    "                ts_feat, **ts_params\n",
    "            ),  # tsfresh + pandas groupby\n",
    "        ],\n",
    "        n_range=[1],\n",
    "        equality_check=False,\n",
    "        labels=[\"functime\", \"tsfresh\"],\n",
    "    )\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_benchmarks_groupby(params: list[tuple]) -> list:\n",
    "    bench_df = pl.DataFrame(\n",
    "        schema={\n",
    "            \"Feature name\": pl.Utf8,\n",
    "            \"n\": pl.Int64,\n",
    "            \"functime + pl groupby (ms)\": pl.Float64,\n",
    "            \"tfresh + pd groupby (ms)\": pl.Float64,\n",
    "            \"diff (ms)\": pl.Float64,\n",
    "            \"diff %\": pl.Float64,\n",
    "            \"speedup\": pl.Float64,\n",
    "        }\n",
    "    )\n",
    "    for x in params:\n",
    "        try:\n",
    "            print(f\"Feature: {x[0].__name__}\")\n",
    "            bench = benchmark_groupby_context(\n",
    "                f_feat=x[0], ts_feat=x[1], f_params=x[2], ts_params=x[3]\n",
    "            )\n",
    "            bench_df = pl.concat(\n",
    "                [\n",
    "                    pl.DataFrame(\n",
    "                        {\n",
    "                            \"Feature name\": [x[0].__name__] * len(bench.n_range),\n",
    "                            \"n\": bench.n_range,\n",
    "                            \"functime + pl groupby (ms)\": bench.timings_s[0] * 1_000,\n",
    "                            \"tfresh + pd groupby (ms)\": bench.timings_s[1] * 1_000,\n",
    "                            \"diff (ms)\": (bench.timings_s[0] - bench.timings_s[1])\n",
    "                            * 1_000,\n",
    "                            \"diff %\": 100\n",
    "                            * (bench.timings_s[0] - bench.timings_s[1])\n",
    "                            / bench.timings_s[1],\n",
    "                            \"speedup\": bench.timings_s[1] / bench.timings_s[0],\n",
    "                        }\n",
    "                    ),\n",
    "                    bench_df,\n",
    "                ]\n",
    "            )\n",
    "        except ValueError:\n",
    "            print(f\"Failed to compute feature {x[0].__name__}\")\n",
    "        except ImportError:\n",
    "            print(f\"Failed to import feature {x[0].__name__}\")\n",
    "        except TypeError:\n",
    "            print(f\"Feature {x[0].__name__} not implemented for pl.Expr\")\n",
    "    return bench_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "bench_groupby = all_benchmarks_groupby(params=FUNC_PARAMS_BENCH)\n",
    "df_groupby = table_prettifier(df=bench_groupby, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S&P500 groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
