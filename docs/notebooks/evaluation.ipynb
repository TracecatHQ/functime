{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Evaluation Procedure\n",
    "This walkthrough covers the `functime.evaluation` module, which contains functions to rank forecasts and time-series features (e.g. tsfresh)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Let's score, rank, and plot point forecasts for multiple commodity prices. We compare two forecasting models:\n",
    "- Seasonal naive (as our benchmark)\n",
    "- AR (autoregressive) LightGBM model with local scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import polars as pl\n",
    "\n",
    "from functime.cross_validation import train_test_split\n",
    "from functime.evaluation import rank_point_forecasts, rank_residuals\n",
    "from functime.forecasting import lightgbm, snaive\n",
    "from functime.plotting import plot_comet, plot_forecasts, plot_fva, plot_residuals\n",
    "from functime.preprocessing import detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 12\n",
    "y = pl.read_parquet(\"../../data/commodities.parquet\")\n",
    "entity_col = y.columns[0]\n",
    "y_train, y_test = train_test_split(test_size=fh, eager=True)(y)\n",
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "There are 71 unique commoditity types and 759 dates (monthly) between and 1960-01-01 and 2023-03-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.select(\n",
    "    pl.all().exclude(\"price\").n_unique(),\n",
    "    pl.col(\"time\").min().dt.date().alias(\"start\"),\n",
    "    pl.col(\"time\").max().dt.date().alias(\"end\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Benchmark Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bench = snaive(freq=\"1mo\", sp=12)(y=y_train, fh=fh)\n",
    "y_pred_bench.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Let's plot the top 4 forecasts by **best** SMAPE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = rank_point_forecasts(y_true=y_test, y_pred=y_pred_bench)\n",
    "ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_entities = ranks.head(4).get_column(entity_col).unique()\n",
    "figure = plot_forecasts(\n",
    "    y_true=y.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    y_pred=y_pred_bench.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    n_cols=2,\n",
    "    height=1000,\n",
    "    width=1200,\n",
    ")\n",
    "figure.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Let's plot the top 3 forecasts by **worst** SMAPE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = rank_point_forecasts(y_true=y_test, y_pred=y_pred_bench, descending=True)\n",
    "ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_entities = ranks.head(4).get_column(entity_col).unique()\n",
    "figure = plot_forecasts(\n",
    "    y_true=y.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    y_pred=y_pred_bench.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    n_cols=2,\n",
    "    height=1000,\n",
    "    width=1200,\n",
    ")\n",
    "figure.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Global AR Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate forecaster and backtest\n",
    "forecaster = lightgbm(freq=\"1mo\", lags=48, target_transform=detrend())\n",
    "y_preds, y_resids = forecaster.backtest(y=y, test_size=12, step_size=12, n_splits=5)\n",
    "y_pred = forecaster(fh=fh, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Let's plot backtests for commodities with the **best** SMAPE score across expanding window splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = rank_point_forecasts(\n",
    "    y_true=y,\n",
    "    y_pred=y_preds,\n",
    ")\n",
    "ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_entities = ranks.head(4).get_column(entity_col).unique()\n",
    "figure = plot_forecasts(\n",
    "    y_true=y.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    y_pred=y_preds.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    n_cols=2,\n",
    "    height=1000,\n",
    "    width=1200,\n",
    ")\n",
    "figure.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Let's plot backtests for commodities with the **worst** SMAPE score across expanding window splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = rank_point_forecasts(y_true=y, y_pred=y_preds, descending=True)\n",
    "ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_entities = ranks.head(4).get_column(entity_col).unique()\n",
    "figure = plot_forecasts(\n",
    "    y_true=y.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    y_pred=y_preds.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    n_cols=2,\n",
    "    height=1000,\n",
    "    width=1200,\n",
    ")\n",
    "figure.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Let's plot residuals for top 10 forecasts ranked by highest mean absolute bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = rank_residuals(y_resids=y_resids, sort_by=\"abs_bias\", descending=True)\n",
    "ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_entities = ranks.head(4).get_column(entity_col).unique()\n",
    "figure = plot_residuals(\n",
    "    y_resids=y_resids.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    n_bins=200,\n",
    "    height=800,\n",
    "    width=1000,\n",
    ")\n",
    "figure.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Let's plot residuals for top 10 forecasts ranked by normality test with the null hypothesis that the residuals are normally distributed. Higher test statistic = more likely to reject null hypothesis under the assumption that the null is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = rank_residuals(y_resids=y_resids, sort_by=\"normality\", descending=True)\n",
    "ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_entities = ranks.head(4).get_column(entity_col).unique()\n",
    "figure = plot_residuals(\n",
    "    y_resids=y_resids.filter(pl.col(entity_col).is_in(selected_entities)),\n",
    "    n_bins=200,\n",
    "    height=800,\n",
    "    width=1000,\n",
    ")\n",
    "figure.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### FVA (Forecast Value Add) Plot\n",
    "It is best-practice to have use a single forecast model as a \"benchmark\". In this walkthrough, we compare seasonal naive forecast to our more \"sophisticated\" autoregressive LightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plot_fva(\n",
    "    y_true=y_test, y_pred=y_pred, y_pred_bench=y_pred_bench, height=900, width=900\n",
    ")\n",
    "figure.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Comet Plot\n",
    "Plot of coefficient of variance (CV) against forecast accuracy (SMAPE by default). CV is the ratio of a patternâ€™s standard deviation to its mean. It expresses the variability of a pattern over time. A flat line would have CV = 0. A highly erratic pattern may have CV of 100% or more. It can be an intuitive heuristic to determine the forecastability across many time-series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plot_comet(\n",
    "    y_train=y_train, y_test=y_test, y_pred=y_pred, height=900, width=900\n",
    ")\n",
    "figure.show(renderer=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "---\n",
    "Coming soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## FFORMA (Feature-based Model Selection)\n",
    "---\n",
    "Coming soon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
