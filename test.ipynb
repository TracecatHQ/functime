{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"a\":range(12)\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pl.col(\"a\")\n",
    "m = 2\n",
    "max_shift = -m + 1\n",
    "n = x.len() - m + 1\n",
    "\n",
    "df.select(\n",
    "    pl.concat_list(x, *(x.shift(-i) for i in range(1,m)))\\\n",
    "    .filter(x.shift(max_shift).is_not_null())\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.examples.robot_execution_failures import download_robot_execution_failures, load_robot_execution_failures\n",
    "import numpy as np \n",
    "import polars as pl\n",
    "\n",
    "\n",
    "download_robot_execution_failures()\n",
    "timeseries, y = load_robot_execution_failures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _into_subchunks(x, subchunk_length, every_n=1):\n",
    "    \"\"\"\n",
    "    Split the time series x into subwindows of length \"subchunk_length\", starting every \"every_n\".\n",
    "\n",
    "    For example, the input data if [0, 1, 2, 3, 4, 5, 6] will be turned into a matrix\n",
    "\n",
    "        0  2  4\n",
    "        1  3  5\n",
    "        2  4  6\n",
    "\n",
    "    with the settings subchunk_length = 3 and every_n = 2\n",
    "    \"\"\"\n",
    "    len_x = len(x)\n",
    "\n",
    "    assert subchunk_length > 1\n",
    "    assert every_n > 0\n",
    "\n",
    "    # how often can we shift a window of size subchunk_length over the input?\n",
    "    num_shifts = (len_x - subchunk_length) // every_n + 1\n",
    "    shift_starts = every_n * np.arange(num_shifts)\n",
    "    indices = np.arange(subchunk_length)\n",
    "\n",
    "    indexer = np.expand_dims(indices, axis=0) + np.expand_dims(shift_starts, axis=1)\n",
    "    return np.asarray(x)[indexer]\n",
    "\n",
    "def tsfresh_sample_entropy(x):\n",
    "    \"\"\"\n",
    "    Calculate and return sample entropy of x.\n",
    "\n",
    "    .. rubric:: References\n",
    "\n",
    "    |  [1] http://en.wikipedia.org/wiki/Sample_Entropy\n",
    "    |  [2] https://www.ncbi.nlm.nih.gov/pubmed/10843903?dopt=Abstract\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "\n",
    "    # if one of the values is NaN, we can not compute anything meaningful\n",
    "    if np.isnan(x).any():\n",
    "        return np.nan\n",
    "\n",
    "    m = 2  # common value for m, according to wikipedia...\n",
    "    tolerance = 0.2 * np.std(\n",
    "        x\n",
    "    )  # 0.2 is a common value for r, according to wikipedia...\n",
    "\n",
    "    # Split time series and save all templates of length m\n",
    "    # Basically we turn [1, 2, 3, 4] into [1, 2], [2, 3], [3, 4]\n",
    "    xm = _into_subchunks(x, m)\n",
    "\n",
    "    # Now calculate the maximum distance between each of those pairs\n",
    "    #   np.abs(xmi - xm).max(axis=1)\n",
    "    # and check how many are below the tolerance.\n",
    "    # For speed reasons, we are not doing this in a nested for loop,\n",
    "    # but with numpy magic.\n",
    "    # Example:\n",
    "    # if x = [1, 2, 3]\n",
    "    # then xm = [[1, 2], [2, 3]]\n",
    "    # so we will substract xm from [1, 2] => [[0, 0], [-1, -1]]\n",
    "    # and from [2, 3] => [[1, 1], [0, 0]]\n",
    "    # taking the abs and max gives us:\n",
    "    # [0, 1] and [1, 0]\n",
    "    # as the diagonal elements are always 0, we substract 1.\n",
    "    B = np.sum([np.sum(np.abs(xmi - xm).max(axis=1) <= tolerance) - 1 for xmi in xm])\n",
    "    # print(B)\n",
    "    # Similar for computing A\n",
    "    xmp1 = _into_subchunks(x, m + 1)\n",
    "\n",
    "    A = np.sum(\n",
    "        [np.sum(np.abs(xmi - xmp1).max(axis=1) <= tolerance) - 1 for xmi in xmp1]\n",
    "    )\n",
    "    # print(A)\n",
    "\n",
    "    # Return SampEn\n",
    "    return -np.log(A / B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 µs ± 2.1 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_into_subchunks(timeseries[timeseries[\"time\"] == 0][\"F_x\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tsfresh_sample_entropy(timeseries[timeseries[\"time\"] == 0][\"F_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functime.feature_extraction.tsfresh import sample_entropy, _into_sequential_chunks\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.from_pandas(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 µs ± 6.86 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_into_sequential_chunks(df.filter(pl.col(\"time\") == 0)[\"F_x\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sample_entropy(df.filter(pl.col(\"time\") == 0)[\"F_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
