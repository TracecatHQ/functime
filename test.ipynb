{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"./data/commodities.parquet\")\n",
    "df_pd = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _into_subchunks(x, subchunk_length, every_n=1):\n",
    "    \"\"\"\n",
    "    Split the time series x into subwindows of length \"subchunk_length\", starting every \"every_n\".\n",
    "\n",
    "    For example, the input data if [0, 1, 2, 3, 4, 5, 6] will be turned into a matrix\n",
    "\n",
    "        0  2  4\n",
    "        1  3  5\n",
    "        2  4  6\n",
    "\n",
    "    with the settings subchunk_length = 3 and every_n = 2\n",
    "    \"\"\"\n",
    "    len_x = len(x)\n",
    "\n",
    "    assert subchunk_length > 1\n",
    "    assert every_n > 0\n",
    "\n",
    "    # how often can we shift a window of size subchunk_length over the input?\n",
    "    num_shifts = (len_x - subchunk_length) // every_n + 1\n",
    "    shift_starts = every_n * np.arange(num_shifts)\n",
    "    indices = np.arange(subchunk_length)\n",
    "\n",
    "    indexer = np.expand_dims(indices, axis=0) + np.expand_dims(shift_starts, axis=1)\n",
    "    return np.asarray(x)[indexer]\n",
    "\n",
    "def tsfresh_sample_entropy(x):\n",
    "    \"\"\"\n",
    "    Calculate and return sample entropy of x.\n",
    "\n",
    "    .. rubric:: References\n",
    "\n",
    "    |  [1] http://en.wikipedia.org/wiki/Sample_Entropy\n",
    "    |  [2] https://www.ncbi.nlm.nih.gov/pubmed/10843903?dopt=Abstract\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "\n",
    "    # if one of the values is NaN, we can not compute anything meaningful\n",
    "    if np.isnan(x).any():\n",
    "        return np.nan\n",
    "\n",
    "    m = 2  # common value for m, according to wikipedia...\n",
    "    tolerance = 0.2 * np.std(\n",
    "        x\n",
    "    )  # 0.2 is a common value for r, according to wikipedia...\n",
    "\n",
    "    # Split time series and save all templates of length m\n",
    "    # Basically we turn [1, 2, 3, 4] into [1, 2], [2, 3], [3, 4]\n",
    "    xm = _into_subchunks(x, m)\n",
    "\n",
    "    # Now calculate the maximum distance between each of those pairs\n",
    "    #   np.abs(xmi - xm).max(axis=1)\n",
    "    # and check how many are below the tolerance.\n",
    "    # For speed reasons, we are not doing this in a nested for loop,\n",
    "    # but with numpy magic.\n",
    "    # Example:\n",
    "    # if x = [1, 2, 3]\n",
    "    # then xm = [[1, 2], [2, 3]]\n",
    "    # so we will substract xm from [1, 2] => [[0, 0], [-1, -1]]\n",
    "    # and from [2, 3] => [[1, 1], [0, 0]]\n",
    "    # taking the abs and max gives us:\n",
    "    # [0, 1] and [1, 0]\n",
    "    # as the diagonal elements are always 0, we substract 1.\n",
    "    B = np.sum([np.sum(np.abs(xmi - xm).max(axis=1) <= tolerance) - 1 for xmi in xm])\n",
    "    # print(B)\n",
    "    # Similar for computing A\n",
    "    xmp1 = _into_subchunks(x, m + 1)\n",
    "\n",
    "    A = np.sum(\n",
    "        [np.sum(np.abs(xmi - xmp1).max(axis=1) <= tolerance) - 1 for xmi in xmp1]\n",
    "    )\n",
    "    # print(A)\n",
    "\n",
    "    # Return SampEn\n",
    "    return -np.log(A / B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeseries[timeseries[\"time\"] == 0][\"F_x\"]\n",
    "tsfresh_sample_entropy(df_pd[\"price\"][:500]) # [:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tsfresh_sample_entropy(df_pd[\"price\"][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functime.feature_extraction.tsfresh import sample_entropy, _into_sequential_chunks\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sample_entropy(df[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _into_sequential_chunks(df[\"price\"], m = 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "tree = KDTree(data)\n",
    "tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tree.query_ball_point(data, r = 0.2 * df[\"price\"].std(ddof=0), p = 1, workers=-1, return_length=True) # - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsfresh.feature_extraction.feature_calculators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _into_sequential_chunks(x:pl.Series, m:int) -> pl.DataFrame:\n",
    "\n",
    "    cname = x.name\n",
    "    n_rows = x.len() - m + 1\n",
    "    df = x.to_frame().select(\n",
    "        pl.col(cname)\n",
    "        , *(pl.col(cname).shift(-i).suffix(str(i)) for i in range(1,m))\n",
    "    ).slice(0, n_rows)\n",
    "    return df # .to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = _into_sequential_chunks(df.filter(pl.col(\"time\") == 0)[\"F_x\"], 2)\n",
    "test1 = test.slice(0, 1)\n",
    "test2 = test.slice(1, None)\n",
    "test1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.select(\n",
    "    pl.when(\n",
    "        pl.max_horizontal(\n",
    "            *((pl.col(c) - pl.lit(test1.item(0,i))) for i, c in enumerate(test2.columns))\n",
    "        ).lt(10.0)\n",
    "    ).then(1).otherwise(0).sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.filter(pl.col(\"time\") == 0)[\"F_x\"]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pl.DataFrame({\n",
    "    \"a\":range(1000),\n",
    "    \"b\":range(1000,2000)\n",
    "})\n",
    "\n",
    "df_test.slice(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df_test.slice(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "np.all(a < 3, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
